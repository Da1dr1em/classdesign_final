#!/usr/bin/env python
"""
å™ªå£°ä¼°è®¡æ–¹æ³•è¯¦ç»†æ¼”ç¤º

å±•ç¤ºVADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰æ–¹æ³•å¦‚ä½•ä¼°è®¡å™ªå£°
"""
import sys
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent / 'src'))

from utils import estimate_noise_vad, frame_signal

def visualize_noise_estimation(audio_file=None):
    """å¯è§†åŒ–å±•ç¤ºå™ªå£°ä¼°è®¡è¿‡ç¨‹"""
    
    print("="*70)
    print("å™ªå£°ä¼°è®¡æ–¹æ³•è¯¦ç»†è¯´æ˜ - åŸºäºVADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰")
    print("="*70)
    
    # å¦‚æœæä¾›äº†éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨å®é™…éŸ³é¢‘ï¼›å¦åˆ™åˆ›å»ºæ¼”ç¤ºä¿¡å·
    if audio_file:
        from utils import load_audio
        signal, sample_rate = load_audio(audio_file)
        print(f"\nä½¿ç”¨å®é™…éŸ³é¢‘: {audio_file}")
        print(f"  é•¿åº¦: {len(signal)} æ ·æœ¬ ({len(signal)/sample_rate:.2f} ç§’)")
    else:
        # åˆ›å»ºæ¼”ç¤ºä¿¡å·ï¼šçº¯éŸ³ + é™éŸ³æ®µ + å™ªå£°
        sample_rate = 44100
        duration = 2
        t = np.linspace(0, duration, int(sample_rate * duration))
        
        # åˆ›å»ºæœ‰è¯´è¯å’Œé™éŸ³äº¤æ›¿çš„ä¿¡å·
        signal = np.zeros_like(t)
        # 0-0.5ç§’: é™éŸ³ï¼ˆåªæœ‰å™ªå£°ï¼‰
        signal[0:int(0.5*sample_rate)] = 0.05 * np.random.randn(int(0.5*sample_rate))
        # 0.5-1.5ç§’: è¯´è¯ï¼ˆ440HzéŸ³è°ƒ + å™ªå£°ï¼‰
        speech_start = int(0.5*sample_rate)
        speech_end = int(1.5*sample_rate)
        signal[speech_start:speech_end] = (
            0.5 * np.sin(2 * np.pi * 440 * t[speech_start:speech_end]) + 
            0.05 * np.random.randn(speech_end - speech_start)
        )
        # 1.5-2ç§’: é™éŸ³ï¼ˆåªæœ‰å™ªå£°ï¼‰
        signal[int(1.5*sample_rate):] = 0.05 * np.random.randn(len(signal) - int(1.5*sample_rate))
        
        print("\nä½¿ç”¨æ¼”ç¤ºä¿¡å·ï¼ˆæ¨¡æ‹Ÿå¯¹è¯åœºæ™¯ï¼‰:")
        print("  0.0-0.5ç§’: é™éŸ³æ®µï¼ˆåªæœ‰å™ªå£°ï¼‰")
        print("  0.5-1.5ç§’: è¯´è¯æ®µï¼ˆè¯­éŸ³+å™ªå£°ï¼‰")
        print("  1.5-2.0ç§’: é™éŸ³æ®µï¼ˆåªæœ‰å™ªå£°ï¼‰")
    
    # å‚æ•°è®¾ç½®
    frame_length = 2048
    hop_length = 512
    energy_threshold_percentile = 20.0
    
    print(f"\n" + "="*70)
    print("æ­¥éª¤1: åˆ†å¸§åˆ†æ")
    print("="*70)
    print(f"  å¸§é•¿åº¦: {frame_length} æ ·æœ¬ ({frame_length/sample_rate*1000:.1f} ms)")
    print(f"  å¸§ç§»: {hop_length} æ ·æœ¬ ({hop_length/sample_rate*1000:.1f} ms)")
    
    # åˆ†å¸§
    frames = frame_signal(signal, frame_length, hop_length)
    print(f"  æ€»å¸§æ•°: {len(frames)}")
    
    print(f"\n" + "="*70)
    print("æ­¥éª¤2: è®¡ç®—æ¯å¸§èƒ½é‡")
    print("="*70)
    
    # è®¡ç®—æ¯å¸§èƒ½é‡
    frame_energy = np.sum(frames ** 2, axis=1)
    print(f"  èƒ½é‡å…¬å¼: E = Î£(xÂ²)")
    print(f"  èƒ½é‡èŒƒå›´: {np.min(frame_energy):.2e} ~ {np.max(frame_energy):.2e}")
    print(f"  èƒ½é‡å‡å€¼: {np.mean(frame_energy):.2e}")
    
    print(f"\n" + "="*70)
    print("æ­¥éª¤3: ç¡®å®šèƒ½é‡é˜ˆå€¼")
    print("="*70)
    
    # ä½¿ç”¨ç™¾åˆ†ä½æ•°ç¡®å®šé˜ˆå€¼
    energy_threshold = np.percentile(frame_energy, energy_threshold_percentile)
    print(f"  æ–¹æ³•: ä½¿ç”¨ç¬¬ {energy_threshold_percentile} ç™¾åˆ†ä½æ•°")
    print(f"  å«ä¹‰: èƒ½é‡æœ€ä½çš„ {energy_threshold_percentile}% çš„å¸§è¢«è®¤ä¸ºæ˜¯\"é™éŸ³æ®µ\"")
    print(f"  é˜ˆå€¼: {energy_threshold:.2e}")
    
    # ç»Ÿè®¡ä½èƒ½é‡å¸§
    silence_mask = frame_energy <= energy_threshold
    num_silence_frames = np.sum(silence_mask)
    print(f"  æ£€æµ‹åˆ°çš„é™éŸ³å¸§æ•°: {num_silence_frames} / {len(frames)} ({num_silence_frames/len(frames)*100:.1f}%)")
    
    print(f"\n" + "="*70)
    print("æ­¥éª¤4: æå–é™éŸ³æ®µä½œä¸ºå™ªå£°æ ·æœ¬")
    print("="*70)
    
    silence_frames = frames[silence_mask]
    print(f"  æå–çš„é™éŸ³å¸§æ•°: {len(silence_frames)}")
    print(f"  é™éŸ³æ®µæ€»æ ·æœ¬æ•°: {len(silence_frames) * frame_length}")
    
    print(f"\n" + "="*70)
    print("æ­¥éª¤5: ç”Ÿæˆå™ªå£°ä¼°è®¡ä¿¡å·")
    print("="*70)
    
    # æ‹¼æ¥å™ªå£°ä¼°è®¡
    noise_estimate = silence_frames.flatten()[:len(signal)]
    
    if len(noise_estimate) < len(signal):
        print(f"  âš ï¸ é™éŸ³æ®µä¸è¶³ï¼Œéœ€è¦æ‰©å±•")
        noise_mean = np.mean(silence_frames)
        noise_std = np.std(silence_frames)
        additional_length = len(signal) - len(noise_estimate)
        print(f"     ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒç”Ÿæˆé¢å¤– {additional_length} ä¸ªæ ·æœ¬")
        print(f"     å‡å€¼: {noise_mean:.4f}, æ ‡å‡†å·®: {noise_std:.4f}")
        additional_noise = np.random.normal(noise_mean, noise_std, additional_length)
        noise_estimate = np.concatenate([noise_estimate, additional_noise])
    
    print(f"  æœ€ç»ˆå™ªå£°ä¼°è®¡é•¿åº¦: {len(noise_estimate)} æ ·æœ¬")
    
    print(f"\n" + "="*70)
    print("æ­¥éª¤6: è®¡ç®—ä¿¡å™ªæ¯”")
    print("="*70)
    
    # è®¡ç®—SNR
    signal_power = np.mean(signal ** 2)
    noise_power = np.mean(noise_estimate ** 2)
    snr_db = 10 * np.log10(signal_power / noise_power)
    
    print(f"  ä¿¡å·åŠŸç‡: {signal_power:.6f}")
    print(f"  å™ªå£°åŠŸç‡: {noise_power:.6f}")
    print(f"  ä¿¡å™ªæ¯” (SNR): {snr_db:.2f} dB")
    print(f"  ")
    print(f"  å…¬å¼: SNR = 10 Ã— logâ‚â‚€(P_signal / P_noise)")
    
    print(f"\n" + "="*70)
    print("ğŸ’¡ å…³é”®ç†è§£")
    print("="*70)
    print("""
1. å™ªå£°ä¼°è®¡çš„å‡è®¾:
   - ä¿¡å·ä¸­å­˜åœ¨"é™éŸ³æ®µ"ï¼ˆä½èƒ½é‡æ®µï¼‰
   - é™éŸ³æ®µä¸»è¦ç”±å™ªå£°ç»„æˆ
   - å™ªå£°åœ¨æ•´æ®µéŸ³é¢‘ä¸­ç›¸å¯¹å¹³ç¨³

2. VADæ–¹æ³•çš„ä¼˜åŠ¿:
   âœ… ä¸éœ€è¦é¢„å…ˆçŸ¥é“å™ªå£°ç‰¹æ€§
   âœ… è‡ªåŠ¨é€‚åº”ä¸åŒçš„éŸ³é¢‘
   âœ… è®¡ç®—ç®€å•é«˜æ•ˆ

3. VADæ–¹æ³•çš„å±€é™:
   âš ï¸ å¦‚æœéŸ³é¢‘ä¸­æ²¡æœ‰é™éŸ³æ®µï¼Œä¼°è®¡ä¼šä¸å‡†ç¡®
   âš ï¸ å¯¹éå¹³ç¨³å™ªå£°ï¼ˆå¦‚çªå‘å™ªå£°ï¼‰æ•ˆæœè¾ƒå·®
   âš ï¸ èƒ½é‡é˜ˆå€¼çš„é€‰æ‹©å½±å“ä¼°è®¡è´¨é‡

4. èƒ½é‡ç™¾åˆ†ä½æ•°çš„å½±å“:
   - 20% (é»˜è®¤): å–èƒ½é‡æœ€ä½çš„20%å¸§ä½œä¸ºå™ªå£°
   - å€¼è¶Šå°: è¶Šä¿å®ˆï¼Œåªå–æœ€å®‰é™çš„éƒ¨åˆ†
   - å€¼è¶Šå¤§: è¶Šæ¿€è¿›ï¼Œå¯èƒ½åŒ…å«éƒ¨åˆ†è¯­éŸ³

5. å®é™…åº”ç”¨:
   - å¯¹äºå¯¹è¯/è¯­éŸ³: æ•ˆæœè¾ƒå¥½ï¼ˆæœ‰è‡ªç„¶åœé¡¿ï¼‰
   - å¯¹äºéŸ³ä¹: æ•ˆæœä¸­ç­‰ï¼ˆå–å†³äºæ˜¯å¦æœ‰é™éŸ³æ®µï¼‰
   - å¯¹äºæŒç»­ä¿¡å·: æ•ˆæœè¾ƒå·®ï¼ˆæ— æ˜æ˜¾é™éŸ³æ®µï¼‰
    """)
    
    # å¯è§†åŒ–ï¼ˆå¦‚æœæ˜¯æ¼”ç¤ºä¿¡å·ï¼‰
    if not audio_file:
        print(f"\n" + "="*70)
        print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        print("="*70)
        
        fig, axes = plt.subplots(3, 1, figsize=(14, 10))
        
        # 1. åŸå§‹ä¿¡å·
        time_axis = np.arange(len(signal)) / sample_rate
        axes[0].plot(time_axis, signal, linewidth=0.5, alpha=0.7)
        axes[0].set_title('åŸå§‹ä¿¡å·ï¼ˆè¯­éŸ³+å™ªå£°ï¼‰', fontsize=14, fontweight='bold')
        axes[0].set_xlabel('æ—¶é—´ (ç§’)')
        axes[0].set_ylabel('å¹…åº¦')
        axes[0].grid(True, alpha=0.3)
        axes[0].axvspan(0, 0.5, alpha=0.2, color='green', label='é™éŸ³æ®µ')
        axes[0].axvspan(0.5, 1.5, alpha=0.2, color='red', label='è¯´è¯æ®µ')
        axes[0].axvspan(1.5, 2.0, alpha=0.2, color='green')
        axes[0].legend()
        
        # 2. å¸§èƒ½é‡
        frame_times = np.arange(len(frame_energy)) * hop_length / sample_rate
        axes[1].plot(frame_times, frame_energy, marker='o', markersize=3, linewidth=1)
        axes[1].axhline(y=energy_threshold, color='r', linestyle='--', linewidth=2, 
                       label=f'èƒ½é‡é˜ˆå€¼ (ç¬¬{energy_threshold_percentile}ç™¾åˆ†ä½)')
        axes[1].fill_between(frame_times, 0, energy_threshold, alpha=0.3, color='green', 
                            label='ä½èƒ½é‡æ®µï¼ˆå™ªå£°ï¼‰')
        axes[1].set_title('æ¯å¸§èƒ½é‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        axes[1].set_xlabel('æ—¶é—´ (ç§’)')
        axes[1].set_ylabel('èƒ½é‡')
        axes[1].set_yscale('log')
        axes[1].grid(True, alpha=0.3)
        axes[1].legend()
        
        # 3. å™ªå£°ä¼°è®¡å¯¹æ¯”
        axes[2].plot(time_axis, signal, linewidth=0.5, alpha=0.5, label='åŸå§‹ä¿¡å·')
        axes[2].plot(time_axis, noise_estimate, linewidth=0.5, alpha=0.7, 
                    label='ä¼°è®¡çš„å™ªå£°', color='orange')
        axes[2].set_title('å™ªå£°ä¼°è®¡ç»“æœ', fontsize=14, fontweight='bold')
        axes[2].set_xlabel('æ—¶é—´ (ç§’)')
        axes[2].set_ylabel('å¹…åº¦')
        axes[2].grid(True, alpha=0.3)
        axes[2].legend()
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        output_path = 'results/figures/noise_estimation_explained.png'
        from utils import ensure_dir
        ensure_dir('results/figures')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"  âœ… å›¾è¡¨å·²ä¿å­˜: {output_path}")
        plt.close()
    
    print(f"\n" + "="*70)
    print("âœ… å™ªå£°ä¼°è®¡è¿‡ç¨‹æ¼”ç¤ºå®Œæˆï¼")
    print("="*70)

if __name__ == "__main__":
    # ä½¿ç”¨æ¼”ç¤ºä¿¡å·
    print("\nã€æ¨¡å¼1: æ¼”ç¤ºä¿¡å·ã€‘\n")
    visualize_noise_estimation()
    
    # ä½¿ç”¨å®é™…éŸ³é¢‘æ–‡ä»¶
    print("\n\nã€æ¨¡å¼2: å®é™…éŸ³é¢‘æ–‡ä»¶ã€‘\n")
    actual_file = r".\data\input\conversation_human.wav"
    import os
    if os.path.exists(actual_file):
        visualize_noise_estimation(actual_file)
    else:
        print(f"è·³è¿‡å®é™…éŸ³é¢‘æµ‹è¯•ï¼ˆæ–‡ä»¶ä¸å­˜åœ¨: {actual_file}ï¼‰")
